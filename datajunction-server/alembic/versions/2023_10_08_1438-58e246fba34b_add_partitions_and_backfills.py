"""Add partitions and backfills

Revision ID: 58e246fba34b
Revises: d8fa1e6371a7
Create Date: 2023-10-08 14:38:06.670157+00:00

"""
# pylint: disable=no-member, invalid-name, missing-function-docstring, unused-import, no-name-in-module

import sqlalchemy as sa
import sqlmodel

from alembic import op

# revision identifiers, used by Alembic.
revision = "58e246fba34b"
down_revision = "d8fa1e6371a7"
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "partition",
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("column_id", sa.Integer(), nullable=False),
        sa.Column("type_", sqlmodel.sql.sqltypes.AutoString(), nullable=False),
        sa.Column("granularity", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.Column("format", sqlmodel.sql.sqltypes.AutoString(), nullable=True),
        sa.ForeignKeyConstraint(
            ["column_id"],
            ["column.id"],
            name=op.f("fk_partition_column_id_column"),
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_partition")),
    )
    op.create_table(
        "backfill",
        sa.Column("spec", sa.JSON(), nullable=True),
        sa.Column("urls", sa.JSON(), nullable=True),
        sa.Column("id", sa.Integer(), nullable=False),
        sa.Column("materialization_id", sa.Integer(), nullable=False),
        sa.ForeignKeyConstraint(
            ["materialization_id"],
            ["materialization.id"],
            name=op.f("fk_backfill_materialization_id_materialization"),
        ),
        sa.PrimaryKeyConstraint("id", name=op.f("pk_backfill")),
    )
    with op.batch_alter_table("column", schema=None) as batch_op:
        batch_op.add_column(sa.Column("partition_id", sa.Integer(), nullable=True))
        batch_op.create_foreign_key(
            batch_op.f("fk_column_partition_id_partition"),
            "partition",
            ["partition_id"],
            ["id"],
        )

    with op.batch_alter_table("materialization", schema=None) as batch_op:
        batch_op.add_column(sa.Column("id", sa.Integer(), nullable=True))
        batch_op.create_unique_constraint(
            "node_revision_engine_uniq",
            ["name", "node_revision_id", "engine_id"],
        )
        batch_op.create_primary_key("materialization_pk", columns=["id"])

    with op.batch_alter_table("materialization", schema=None) as batch_op:
        batch_op.alter_column("id", nullable=False)


def downgrade():
    with op.batch_alter_table("materialization", schema=None) as batch_op:
        batch_op.drop_constraint("node_revision_engine_uniq", type_="unique")
        batch_op.drop_column("id")

    with op.batch_alter_table("column", schema=None) as batch_op:
        batch_op.drop_constraint(
            batch_op.f("fk_column_partition_id_partition"),
            type_="foreignkey",
        )
        batch_op.drop_column("partition_id")

    op.drop_table("backfill")
    op.drop_table("partition")
